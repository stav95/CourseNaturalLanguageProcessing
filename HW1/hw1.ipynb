{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from itertools import tee\n",
    "from os.path import join as pj\n",
    "from typing import List, Union, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_FOLDER = pj('thesis', 'NLP_Course', 'HW1', 'data')\n",
    "START_TOKEN = '<s>'\n",
    "END_TOKEN = '</s>'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "def get_tweets_from_file(data_file_path: Union[str, os.PathLike]) -> List[str]:\n",
    "    return pd.read_csv(data_file_path, encoding='utf-8')['tweet_text'].tolist()\n",
    "\n",
    "\n",
    "def preprocess() -> List[str]:\n",
    "    vocabulary = {START_TOKEN, END_TOKEN}\n",
    "    for f in os.listdir(DATA_FOLDER):\n",
    "        if f.endswith('.csv'):\n",
    "            print(f)\n",
    "            for tweet in get_tweets_from_file(data_file_path=pj(DATA_FOLDER, f)):\n",
    "                vocabulary.update(tweet)\n",
    "\n",
    "    return list(vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en.csv\n",
      "fr.csv\n",
      "tl.csv\n",
      "pt.csv\n",
      "es.csv\n",
      "it.csv\n",
      "nl.csv\n",
      "in.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1804, ['🦄', '😞', '🌫', '녀', '🐓', '🗾', '●', 'А', '🐶', 'p'])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_vocabulary = preprocess()\n",
    "len(_vocabulary), _vocabulary[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def pad_sequence(sequence: str, n: int, pad_left: bool = True, pad_right: bool = True,\n",
    "                 left_pad_symbol: str = START_TOKEN, right_pad_symbol: str = END_TOKEN):\n",
    "    sequence = iter(sequence)\n",
    "    if pad_left:\n",
    "        sequence = chain((left_pad_symbol,) * (n - 1), sequence)\n",
    "    if pad_right:\n",
    "        sequence = chain(sequence, (right_pad_symbol,) * (n - 1))\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def ngram(sequence: str, n: int) -> zip:\n",
    "    sequence = pad_sequence(sequence=sequence, n=n)\n",
    "\n",
    "    iterables = tee(sequence, n)\n",
    "\n",
    "    for i, sub_iterable in enumerate(iterables):\n",
    "        for _ in range(i):\n",
    "            next(sub_iterable, None)\n",
    "\n",
    "    return zip(*iterables)\n",
    "\n",
    "\n",
    "def get_ngram_model(grams: List[Tuple[str, ...]],\n",
    "                    vocab_length: int, add_one: bool = False) -> Dict[str, Dict[str, float]]:\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 1e-8))\n",
    "\n",
    "    for gram in grams:\n",
    "        list_gram = list(gram)\n",
    "        last_ch = list_gram.pop(len(list_gram) - 1)\n",
    "        seq = ''.join(list_gram)\n",
    "        model[seq][last_ch] += 1\n",
    "\n",
    "    for seq in model.keys():\n",
    "        counter = 0\n",
    "        for last_ch in model[seq].keys():\n",
    "            counter += model[seq][last_ch]\n",
    "        for last_ch in model[seq].keys():\n",
    "            model[seq][last_ch] = (model[seq][last_ch] + (1 * add_one)) / (counter + (vocab_length * add_one))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def lm(n: int, vocabulary: List[str], data_file_path: Union[str, os.PathLike],\n",
    "       add_one: bool = False) -> Dict[str, Dict[str, float]]:\n",
    "    # n - the n-gram to use (e.g., 1 - unigram, 2 - bigram, etc.)\n",
    "    # vocabulary - the vocabulary list (which you should use for calculating add_one smoothing)\n",
    "    # data_file_path - the data_file from which we record probabilities for our model\n",
    "    # add_one - True/False (use add_one smoothing or not)\n",
    "    v_len = len(vocabulary)\n",
    "\n",
    "    tweets = get_tweets_from_file(data_file_path=data_file_path)\n",
    "    grams = [gram for seq in tweets for gram in ngram(sequence=seq, n=n)]\n",
    "\n",
    "    return get_ngram_model(grams=grams, vocab_length=v_len, add_one=add_one)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "_model_3 = lm(n=3, vocabulary=_vocabulary, data_file_path=pj(DATA_FOLDER, 'en.csv'), add_one=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "8.695300683714246"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _eval(n: int, model: Dict[str, Dict[str, float]], data_file: str) -> float:\n",
    "    # n - the n-gram that you used to build your model (must be the same number)\n",
    "    # model - the dictionary (model) to use for calculating perplexity\n",
    "    # data_file - the tweets file that you wish to calculate a perplexity score for\n",
    "\n",
    "    tweets = get_tweets_from_file(data_file_path=pj(DATA_FOLDER, data_file))\n",
    "    probs = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        # Start of the sentence.\n",
    "        probs += [model[START_TOKEN * (n - i - 1) + tweet[:i]][tweet[i]]\n",
    "                  for i in range(n - 1)]\n",
    "        # n-grams of the sentence.\n",
    "        probs += [model[tweet[i:i + n - 1]][tweet[i + n - 1]]\n",
    "                  for i in range(len(tweet) - n + 1)]\n",
    "        # End of sentence.\n",
    "        last_idx = len(tweet) - n + 1\n",
    "        probs += [model[tweet[last_idx + i:last_idx + n] + END_TOKEN * i][END_TOKEN]\n",
    "                  for i in range(n - 1)]\n",
    "\n",
    "    return np.power(2, - np.log2(probs).mean())\n",
    "\n",
    "\n",
    "_eval(n=3, model=_model_3, data_file='en.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def match(n: int, add_one: bool) -> pd.DataFrame:\n",
    "    # n - the n-gram to use for creating n-gram models\n",
    "    # add_one - use add_one smoothing or not\n",
    "\n",
    "    #TODO\n",
    "\n",
    "    languages = {os.path.splitext(fn)[0]: fn\n",
    "                 for fn in os.listdir(DATA_FOLDER) if fn.endswith('.csv')}\n",
    "    languages.pop('test')\n",
    "    languages.pop('tests')\n",
    "\n",
    "    vocabulary = preprocess()\n",
    "\n",
    "    models = {}\n",
    "    languages_sorted = sorted(list(languages.keys()))\n",
    "    for language in languages_sorted:\n",
    "        models[language] = lm(n=n, vocabulary=vocabulary,\n",
    "                              data_file_path=pj(DATA_FOLDER, languages[language]), add_one=add_one)\n",
    "\n",
    "    df = pd.DataFrame(columns=languages_sorted)\n",
    "    for lang_model in languages_sorted:\n",
    "        for lang_test in languages_sorted:\n",
    "            prep = _eval(n=n, model=models[lang_model], data_file=languages[lang_test])\n",
    "            df.loc[lang_model, lang_test] = round(prep, 4)\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def run_match():\n",
    "    for n in [1, 2, 3, 4]:\n",
    "        for add_one in [True, False]:\n",
    "            print(f\"{'-' * 20} n = {n}, add one = {add_one} {'-' * 20}\")\n",
    "            print(match(n=n, add_one=add_one))\n",
    "            print('\\n')\n",
    "\n",
    "#TODO\n",
    "run_match()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def match2(n: int, add_one: bool) -> Dict[str, Dict[str, Dict[str, float]]]:\n",
    "    # n - the n-gram to use for creating n-gram models\n",
    "    # add_one - use add_one smoothing or not\n",
    "\n",
    "    #TODO\n",
    "\n",
    "    languages = {os.path.splitext(fn)[0]: fn\n",
    "                 for fn in os.listdir(DATA_FOLDER) if fn.endswith('.csv')}\n",
    "    languages.pop('test')\n",
    "    languages.pop('tests')\n",
    "\n",
    "    vocabulary = preprocess()\n",
    "\n",
    "    models = {}\n",
    "    languages_sorted = sorted(list(languages.keys()))\n",
    "    for language in languages_sorted:\n",
    "        models[language] = lm(n=n, vocabulary=vocabulary,\n",
    "                              data_file_path=pj(DATA_FOLDER, languages[language]), add_one=add_one)\n",
    "\n",
    "    df = pd.DataFrame(columns=languages_sorted)\n",
    "    for lang_model in languages_sorted:\n",
    "        for lang_test in languages_sorted:\n",
    "            prep = _eval(n=n, model=models[lang_model], data_file=languages[lang_test])\n",
    "            df.loc[lang_model, lang_test] = round(prep, 4)\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def run_match2() -> Dict[str, Dict[str, Dict[str, Dict[str, float]]]]:\n",
    "    all_models = {}\n",
    "    for n in [1, 2, 3, 4, 5]:\n",
    "        for add_one in [True, False]:\n",
    "            all_models[f'{n}_{str(add_one)[0]}'] = match2(n=n, add_one=add_one)\n",
    "\n",
    "    return all_models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['1_T', '1_F', '2_T', '2_F', '3_T', '3_F', '4_T', '4_F', '5_T', '5_F'])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_all_models = run_match2()\n",
    "_all_models.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "_df_test = pd.read_csv(pj(DATA_FOLDER, 'test.csv'))\n",
    "_tweets, _labels = _df_test['tweet_text'].tolist(), _df_test['label'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def sum_word_prob(models: Dict[str, Dict[str, Dict[str, Dict[str, float]]]], word: str) -> Dict[str, float]:\n",
    "    word_sum = defaultdict(lambda: 0.0)\n",
    "\n",
    "    def _s(_m: Dict[str, Dict[str, Dict[str, Dict[str, float]]]], _w: str, _ws: Dict[str, float], gram_value: int):\n",
    "        for i in range(len(_w) - gram_value + 1):\n",
    "            for lang in models[f'{gram_value}_T'].keys():\n",
    "                _ws[lang] += _m[f'{gram_value}_T'][lang][_w[i: i + gram_value - 1]][_w[i + gram_value - 1]]\n",
    "                _ws[lang] += _m[f'{gram_value}_F'][lang][_w[i: i + gram_value - 1]][_w[i + gram_value - 1]]\n",
    "\n",
    "    for j in list(set([m.split('_')[0] for m in models.keys()])):\n",
    "        _s(_m=models, _w=word, _ws=word_sum, gram_value=int(j))\n",
    "\n",
    "    return word_sum\n",
    "\n",
    "\n",
    "def sum_words_prob(models: Dict[str, Dict[str, Dict[str, Dict[str, float]]]], sequence: str) -> Dict[str, float]:\n",
    "    t = sequence[:]\n",
    "    t = re.sub('#[^ ]*', '', t)\n",
    "    t = re.sub('[0-9]*', '', t)\n",
    "    t = re.sub('https://t.co/[a-zA-Z0-9]*', '', t)\n",
    "    words = re.findall(\"[^ ]+\", t, flags=re.IGNORECASE)\n",
    "\n",
    "    sums = defaultdict(lambda: 0.0)\n",
    "\n",
    "    for word in words:\n",
    "        for l, v in sum_word_prob(models=models, word=word).items():\n",
    "            sums[l] += v\n",
    "\n",
    "    return sums\n",
    "\n",
    "\n",
    "def classify(models: Dict[str, Dict[str, Dict[str, Dict[str, float]]]],\n",
    "             tweets: List[str]) -> List[str]:\n",
    "    def _classify(_models: Dict[str, Dict[str, Dict[str, Dict[str, float]]]], sequence: str) -> str:\n",
    "        swords = sum_words_prob(models=models, sequence=sequence)\n",
    "        if len(swords) == 0:\n",
    "            return 'en'  # there are few without words so just returning en can be any language, it doens't matter\n",
    "\n",
    "        return sorted([(l, v) for l, v in swords.items()], key=lambda x: x[1])[-1][0]\n",
    "\n",
    "    predictions = []\n",
    "    for t in tweets:\n",
    "        predictions.append(_classify(_models=models, sequence=t))\n",
    "\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def calc_f1(result: Dict[str, List[str]]):\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    labels, predictions = result['labels'], result['predictions']\n",
    "    correct = sum([1 for l, p in zip(labels, predictions) if l.__eq__(p)])\n",
    "    print(f'Total samples: {len(labels)}')\n",
    "    print(f'Classified correct: {correct} & Classified wrong: {len(labels) - correct}.')\n",
    "    print(f'F1 score: {round(f1_score(labels, predictions, average=\"macro\"), 5)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "clasification_result = classify(models=_all_models, tweets=_tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 7999\n",
      "Classified correct: 7228 & Classified wrong: 771.\n",
      "F1 score: 0.90382\n"
     ]
    }
   ],
   "source": [
    "calc_f1(result={'labels': _labels, 'predictions': clasification_result})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}